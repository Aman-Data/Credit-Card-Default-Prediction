ğŸ“„ Project Title:

"Predicting Credit Card Default Risk Using Machine Learning"

---

ğŸ“Œ Objective:

To develop a machine learning model that predicts the likelihood of a customer defaulting on a credit card payment based on demographic and financial data.

---

ğŸ“Š Dataset Information:

* **Source:** UCI Machine Learning Repository
* **Name:** Default of Credit Card Clients Dataset (Taiwan)
* **Duration:** April 2005 â€“ September 2005
* **Total Observations:** 30,000 records
* **Features:**

  * **Demographics:** Age, Gender, Education, Marital Status
  * **Credit Limit:** LIMIT\_BAL
  * **Payment History:** PAY\_0 to PAY\_6
  * **Bill Statement Amounts:** BILL\_AMT1 to BILL\_AMT6
  * **Previous Payments:** PAY\_AMT1 to PAY\_AMT6
  * **Target Variable:** `default.payment.next.month` (0 = No, 1 = Yes)

---

ğŸ› ï¸ Technologies Used:

* **Language:** Python
* **Libraries:** pandas, numpy, scikit-learn, matplotlib, seaborn, streamlit
* **Environment:** Jupyter Notebook, VS Code
* **App Framework:** Streamlit

---

ğŸ§¹ Data Pipeline Overview:

1. **Data Collection**

* Loaded dataset and checked for nulls, duplicates.

2. **Data Cleaning**

* Renamed columns for clarity.
* Removed duplicates if any.
* Handled outliers using IQR method or capping.

3. **Preprocessing**

* Encoded categorical features (e.g., gender, education).
* Feature scaling using StandardScaler for models sensitive to scale.
* Split into **X** and **y**, then into **train-test sets** (e.g., 80/20 split).

4. **Exploratory Data Analysis (EDA)**

* Visualized distributions (e.g., age, limit balance).
* Correlation heatmap.
* Class imbalance checked.

---

ğŸ” Model Building:

Model Tried:

* **Logistic Regression**
* **Decision Tree**
* âœ… **Random Forest (Best performing)**

### Best Model: **Random Forest Classifier**

* **Accuracy:** 84%
* **Precision (Class 1):** 0.85
* **Recall (Class 1):** 0.82
* **F1 Score (Class 1):** 0.83

```text
              precision    recall  f1-score   support

           0       0.82      0.86      0.84      7010
           1       0.85      0.82      0.83      7009

    Accuracy:                         0.84     14019
```

---

ğŸŒ Deployment: Streamlit App

* A user-friendly web app was built using **Streamlit**.
* Takes user input (or pre-set test case) for all 23 features.
* Predicts and displays:

  * âœ… **Low risk of default** (if predicted class is 0)
  * âš ï¸ **High risk of default** (if predicted class is 1)

---

ğŸ“ Project Structure:

```
MLENDTOEND/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ rawdata/
â”‚   â”œâ”€â”€ cleaneddata/
â”‚   â””â”€â”€ preprocessdata/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pkl               # Trained Random Forest model
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ datacollection.ipynb
â”‚   â”œâ”€â”€ datacleaning.ipynb
â”‚   â”œâ”€â”€ preprocess.ipynb
â”‚   â”œâ”€â”€ eda.ipynb
â”‚   â””â”€â”€ modelbuilding.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ datacollection.py
â”‚   â”œâ”€â”€ datacleaning.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ modelbuilding.py
â”‚
â”œâ”€â”€ app.py                      # Streamlit app
â””â”€â”€ requirements.txt            # Environment setup
```

---

âœ… Key Learnings:

* End-to-end pipeline from raw data to deployed model.
* Feature engineering and model evaluation.
* Deploying models using Streamlit.
* Interpreting precision-recall tradeoffs.

---

ğŸ“¦ Future Improvements:

* Use SMOTE to handle class imbalance.
* Deploy with Docker on cloud (e.g., Heroku, AWS).
* Add SHAP for explainable AI insights.